{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding1D, BatchNormalization, Flatten, Conv1D, AveragePooling1D, MaxPooling1D, GlobalMaxPooling2D, LeakyReLU, GlobalAveragePooling2D, ReLU, concatenate\n",
    "from tensorflow.keras.initializers import glorot_uniform, constant\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "import data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import filters\n",
    "import json\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_block(X, f, s, filters, stage, block, dil=1):\n",
    "   \n",
    "    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value. You'll need this later to add back to the main path. \n",
    "    X_shortcut = X\n",
    "    \n",
    "    # First component of main path\n",
    "    X = Conv1D(filters = F1, kernel_size = 1, strides = s, dilation_rate=dil, padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(momentum = 0.9, name = bn_name_base + '2a')(X)\n",
    "    X = Activation(ReLU())(X)\n",
    "\n",
    "    # Second component of main path (≈3 lines)\n",
    "    X = Conv1D(filters = F2, kernel_size = f, strides = 1, dilation_rate=dil, padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(momentum=0.9, name=bn_name_base + '2b')(X)\n",
    "    X = Activation(ReLU())(X)\n",
    "\n",
    "    # Third component of main path (≈2 lines)\n",
    "    X = Conv1D(filters = F3, kernel_size = 1, strides = 1, dilation_rate=dil, padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(momentum = 0.9, name = bn_name_base + '2c')(X)\n",
    "    \n",
    "    # side me\n",
    "    X_shortcut = Conv1D(filters = F3, kernel_size = 1, strides = s, padding = 'valid', name = conv_name_base + '1',\n",
    "                        kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization( momentum = 0.9, name = bn_name_base + '1')(X_shortcut)\n",
    "    \n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation(ReLU())(X)\n",
    "    # X = BatchNormalization(momentum = 0.9, name = bn_name_base + '2c')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50_1D(data_in_shape, num_output=2, fs=1000, UseDerivative=False):\n",
    "    \"\"\"\n",
    "    Implementation of the popular ResNet50 the following architecture:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(shape=data_in_shape)\n",
    "\n",
    "    if UseDerivative:\n",
    "        dt1 = (X_input[:,1:] - X_input[:,:-1])*fs\n",
    "        dt2 = (dt1[:,1:] - dt1[:,:-1])*fs\n",
    "\n",
    "        dt1 = tf.pad(dt1, tf.constant([[0,0],[0,1],[0,0]]))\n",
    "        dt2 = tf.pad(dt2, tf.constant([[0,0],[0,2],[0,0]]))\n",
    "\n",
    "        X = tf.concat([X_input, dt1, dt2], axis=2)\n",
    "    else:\n",
    "        X=X_input\n",
    "\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding1D(3)(X_input)\n",
    "\n",
    "    # Stage 1\n",
    "    X = Conv1D(64, 7, strides=2, name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=2, name='bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = ZeroPadding1D(3)(X)\n",
    "    X = MaxPooling1D(3, strides=3)(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = resnet_block(X, 3, 1, [64, 64, 256], stage=2, block='a')\n",
    "    X = resnet_block(X, 3, 1, [64, 64, 256], stage=2, block='b')\n",
    "    X = resnet_block(X, 3, 1, [64, 64, 256], stage=2, block='c')\n",
    "    X = resnet_block(X, 3, 1, [64, 64, 256], stage=2, block='d')\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Stage 3 (≈4 lines)\n",
    "    X = resnet_block(X, 3, 2, [128, 128, 512], stage=3, block='a')\n",
    "    X = resnet_block(X, 3, 1, [128, 128, 512], stage=3, block='b')\n",
    "    X = resnet_block(X, 3, 1, [128, 128, 512], stage=3, block='c')\n",
    "    X = resnet_block(X, 3, 1, [128, 128, 512], stage=3, block='d')\n",
    "    \n",
    "    # Stage 4 (≈6 lines)\n",
    "    X = resnet_block(X, 3, 2, [256, 256, 1024], stage=4, block='a')\n",
    "    X = resnet_block(X, 3, 1, [256, 256, 1024], stage=4, block='b')\n",
    "    X = resnet_block(X, 3, 1, [256, 256, 1024], stage=4, block='c')\n",
    "    X = resnet_block(X, 3, 1, [256, 256, 1024], stage=4, block='d')\n",
    "    \n",
    "    # Stage 5 (≈3 lines)\n",
    "    X = resnet_block(X, 3, 2, [512, 512, 2048], stage=5, block='a')\n",
    "    X = resnet_block(X, 3, 1, [512, 512, 2048], stage=5, block='b')\n",
    "    X = resnet_block(X, 3, 1, [512, 512, 2048], stage=5, block='c')\n",
    "    X = resnet_block(X, 3, 2, [512, 512, 2048], stage=5, block='d')\n",
    "    X = resnet_block(X, 3, 1, [512, 512, 2048], stage=5, block='e')\n",
    "    \n",
    "    \n",
    "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
    "    X = AveragePooling1D(2, name=\"avg_pool\")(X)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X_SBP = Dense(1, activation='linear', name='SBP', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X_DBP = Dense(1, activation='linear', name='DBP', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    HR = Dense(1, activation='linear', name='HR', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    # Create model\n",
    "    if num_output==3:\n",
    "        model = Model(inputs=X_input, outputs=[X_SBP, X_DBP, HR], name='ResNet50_1D')\n",
    "    else:\n",
    "        model = Model(inputs = X_input, outputs = [X_SBP, X_DBP], name='ResNet50_1D')\n",
    "\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76d7c06053c3456e5600312cec90888656fc0ed30c03d8425b9dac6e4fc8e014"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
